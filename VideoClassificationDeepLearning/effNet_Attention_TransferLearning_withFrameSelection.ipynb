{"cells":[{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2023-04-21T19:31:14.291252Z","iopub.status.busy":"2023-04-21T19:31:14.290549Z","iopub.status.idle":"2023-04-21T19:31:14.298102Z","shell.execute_reply":"2023-04-21T19:31:14.296912Z","shell.execute_reply.started":"2023-04-21T19:31:14.291214Z"},"trusted":true},"outputs":[],"source":["import cv2\n","import numpy as np\n","import random\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import keras\n","from sklearn.model_selection import train_test_split\n","import tensorflow as tf\n","from tensorflow.keras.layers import *\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.utils import to_categorical\n","from tensorflow.keras.callbacks import EarlyStopping\n","from tensorflow.keras.utils import plot_model\n","from tensorflow.keras import datasets, applications"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2023-04-21T19:31:15.360227Z","iopub.status.busy":"2023-04-21T19:31:15.359852Z","iopub.status.idle":"2023-04-21T19:31:15.368821Z","shell.execute_reply":"2023-04-21T19:31:15.367519Z","shell.execute_reply.started":"2023-04-21T19:31:15.360197Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["{'ApplyEyeMakeup': 1, 'ApplyLipstick': 2, 'Archery': 3, 'BabyCrawling': 4, 'BalanceBeam': 5, 'BandMarching': 6, 'BaseballPitch': 7, 'Basketball': 8, 'BasketballDunk': 9, 'BenchPress': 10, 'Biking': 11, 'Billiards': 12, 'BlowDryHair': 13, 'BlowingCandles': 14, 'BodyWeightSquats': 15, 'Bowling': 16, 'BoxingPunchingBag': 17, 'BoxingSpeedBag': 18, 'BreastStroke': 19, 'BrushingTeeth': 20, 'CleanAndJerk': 21, 'CliffDiving': 22, 'CricketBowling': 23, 'CricketShot': 24, 'CuttingInKitchen': 25, 'Diving': 26, 'Drumming': 27, 'Fencing': 28, 'FieldHockeyPenalty': 29, 'FloorGymnastics': 30, 'FrisbeeCatch': 31, 'FrontCrawl': 32, 'GolfSwing': 33, 'Haircut': 34, 'Hammering': 35, 'HammerThrow': 36, 'HandstandPushups': 37, 'HandstandWalking': 38, 'HeadMassage': 39, 'HighJump': 40, 'HorseRace': 41, 'HorseRiding': 42, 'HulaHoop': 43, 'IceDancing': 44, 'JavelinThrow': 45, 'JugglingBalls': 46, 'JumpingJack': 47, 'JumpRope': 48, 'Kayaking': 49, 'Knitting': 50, 'LongJump': 51, 'Lunges': 52, 'MilitaryParade': 53, 'Mixing': 54, 'MoppingFloor': 55, 'Nunchucks': 56, 'ParallelBars': 57, 'PizzaTossing': 58, 'PlayingCello': 59, 'PlayingDaf': 60, 'PlayingDhol': 61, 'PlayingFlute': 62, 'PlayingGuitar': 63, 'PlayingPiano': 64, 'PlayingSitar': 65, 'PlayingTabla': 66, 'PlayingViolin': 67, 'PoleVault': 68, 'PommelHorse': 69, 'PullUps': 70, 'Punch': 71, 'PushUps': 72, 'Rafting': 73, 'RockClimbingIndoor': 74, 'RopeClimbing': 75, 'Rowing': 76, 'SalsaSpin': 77, 'ShavingBeard': 78, 'Shotput': 79, 'SkateBoarding': 80, 'Skiing': 81, 'Skijet': 82, 'SkyDiving': 83, 'SoccerJuggling': 84, 'SoccerPenalty': 85, 'StillRings': 86, 'SumoWrestling': 87, 'Surfing': 88, 'Swing': 89, 'TableTennisShot': 90, 'TaiChi': 91, 'TennisSwing': 92, 'ThrowDiscus': 93, 'TrampolineJumping': 94, 'Typing': 95, 'UnevenBars': 96, 'VolleyballSpiking': 97, 'WalkingWithDog': 98, 'WallPushups': 99, 'WritingOnBoard': 100, 'YoYo': 101}\n"]}],"source":["#use this string for the path to the folder containing all the images in kaggle\n","\n","folder_path = '/kaggle/input/ucf101/'\n","\n","class_indices_file = open(folder_path+ 'UCF101TrainTestSplits-RecognitionTask/ucfTrainTestlist/classInd.txt', 'r')\n","class_index = {}\n","for line in class_indices_file:\n","    class_ = line.split(' ')\n","    class_index[class_[1].strip('\\n')] = int(class_[0])\n","    \n","class_indices_file.close()\n","\n","print(class_index)"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2023-04-21T19:31:15.813432Z","iopub.status.busy":"2023-04-21T19:31:15.813030Z","iopub.status.idle":"2023-04-21T19:31:15.822860Z","shell.execute_reply":"2023-04-21T19:31:15.821625Z","shell.execute_reply.started":"2023-04-21T19:31:15.813395Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["[['ApplyEyeMakeup', 'ApplyLipstick'], ['Basketball', 'BasketballDunk'], ['CricketBowling', 'CricketShot'], ['FloorGymnastics'], ['SumoWrestling'], ['PullUps'], ['PushUps'], ['WritingOnBoard'], ['PlayingCello', 'PlayingDaf', 'PlayingDhol', 'PlayingFlute', 'PlayingGuitar', 'PlayingPiano', 'PlayingSitar', 'PlayingTabla', 'PlayingViolin'], ['SkyDiving'], ['WalkingWithDog'], ['FieldHockeyPenalty'], ['SoccerPenalty'], ['Shotput'], ['SkateBoarding'], ['SoccerJuggling'], ['LongJump'], ['JavelinThrow'], ['SalsaSpin'], ['Rafting'], ['IceDancing']]\n"]}],"source":["req_classes = [[1,2], [8,9], [23,24], [30], [87], [70], [72], [100], [59,60,61,62,63,64,65,66,67], \n","               [83],[98], [29], [85], [79], [80], [84], [51], [45], [77], [73], [44]]\n","\n","class_names = []\n","for _ in req_classes:\n","    classes = []\n","    for __ in _:\n","      classes.append([key for key in list(class_index.keys()) if class_index[key] == __][0])\n","    class_names.append(classes)\n","print(class_names)\n"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2023-04-21T19:31:16.323479Z","iopub.status.busy":"2023-04-21T19:31:16.322640Z","iopub.status.idle":"2023-04-21T19:31:16.335308Z","shell.execute_reply":"2023-04-21T19:31:16.333593Z","shell.execute_reply.started":"2023-04-21T19:31:16.323434Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["{1: 1, 2: 1, 8: 2, 9: 2, 23: 3, 24: 3, 30: 4, 87: 5, 70: 6, 72: 7, 100: 8, 59: 9, 60: 9, 61: 9, 62: 9, 63: 9, 64: 9, 65: 9, 66: 9, 67: 9, 83: 10, 98: 11, 29: 12, 85: 13, 79: 14, 80: 15, 84: 16, 51: 17, 45: 18, 77: 19, 73: 20, 44: 21}\n"]}],"source":["label_dict = {}\n","\n","label = 1\n","for _ in req_classes:\n","    for id in _:\n","        label_dict[id] = label\n","    label += 1\n","\n","print(label_dict)"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2023-04-21T19:31:16.600086Z","iopub.status.busy":"2023-04-21T19:31:16.599319Z","iopub.status.idle":"2023-04-21T19:31:16.623394Z","shell.execute_reply":"2023-04-21T19:31:16.622359Z","shell.execute_reply.started":"2023-04-21T19:31:16.600043Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["[1, 2, 8, 9, 23, 24, 30, 87, 70, 72, 100, 59, 60, 61, 62, 63, 64, 65, 66, 67, 83, 98, 29, 85, 79, 80, 84, 51, 45, 77, 73, 44]\n"]}],"source":["#considering only one test train split 01\n","train_path_file = open(folder_path + \"UCF101TrainTestSplits-RecognitionTask/ucfTrainTestlist/trainlist01.txt\", \"r\")\n","train_path_list = []\n","train_y = []\n","# print(next(train_path_file))\n","list_req_class = [i for l in req_classes for i in l]\n","print(list_req_class)\n","for _ in train_path_file:\n","    path, class_num = _.split(' ')\n","    if (int(class_num.strip('\\n')) in list_req_class):\n","        train_path_list.append(path)\n","        train_y.append(label_dict[int(class_num.strip('\\n'))])\n","        #print(int(label_dict[class_num.strip('\\n')]))\n","    \n","train_path_file.close()\n"]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2023-04-21T19:31:16.810342Z","iopub.status.busy":"2023-04-21T19:31:16.809374Z","iopub.status.idle":"2023-04-21T19:31:16.817600Z","shell.execute_reply":"2023-04-21T19:31:16.816199Z","shell.execute_reply.started":"2023-04-21T19:31:16.810302Z"},"trusted":true},"outputs":[{"data":{"text/plain":["3035"]},"execution_count":16,"metadata":{},"output_type":"execute_result"}],"source":["len(train_path_list)"]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2023-04-21T19:31:17.067994Z","iopub.status.busy":"2023-04-21T19:31:17.066760Z","iopub.status.idle":"2023-04-21T19:31:17.082776Z","shell.execute_reply":"2023-04-21T19:31:17.081610Z","shell.execute_reply.started":"2023-04-21T19:31:17.067949Z"},"trusted":true},"outputs":[],"source":["test_path_file = open(folder_path + \"UCF101TrainTestSplits-RecognitionTask/ucfTrainTestlist/testlist01.txt\", \"r\")\n","test_path_list = []\n","test_y = []\n","# print(next(test_path_file))\n","for _ in test_path_file:\n","    path = _.strip('\\n')\n","    a,b = path.split('/')\n","    if (class_index[a] in list_req_class):\n","        test_path_list.append(path)\n","        test_y.append(label_dict[class_index[a]])\n","\n","\n","test_path_file.close()\n","\n"]},{"cell_type":"code","execution_count":18,"metadata":{"execution":{"iopub.execute_input":"2023-04-21T19:31:17.230331Z","iopub.status.busy":"2023-04-21T19:31:17.229667Z","iopub.status.idle":"2023-04-21T19:31:17.237533Z","shell.execute_reply":"2023-04-21T19:31:17.236295Z","shell.execute_reply.started":"2023-04-21T19:31:17.230295Z"},"trusted":true},"outputs":[{"data":{"text/plain":["1214"]},"execution_count":18,"metadata":{},"output_type":"execute_result"}],"source":["len(test_path_list)"]},{"cell_type":"code","execution_count":19,"metadata":{"execution":{"iopub.execute_input":"2023-04-21T19:31:17.447264Z","iopub.status.busy":"2023-04-21T19:31:17.446624Z","iopub.status.idle":"2023-04-21T19:31:17.456358Z","shell.execute_reply":"2023-04-21T19:31:17.455038Z","shell.execute_reply.started":"2023-04-21T19:31:17.447232Z"},"trusted":true},"outputs":[],"source":["# Using Keras's to_categorical method to convert labels into one-hot-encoded vectors\n","train_y_hot = pd.get_dummies(train_y)\n","test_y_hot = pd.get_dummies(test_y)"]},{"cell_type":"code","execution_count":20,"metadata":{"execution":{"iopub.execute_input":"2023-04-21T19:31:17.620706Z","iopub.status.busy":"2023-04-21T19:31:17.619864Z","iopub.status.idle":"2023-04-21T19:31:18.312151Z","shell.execute_reply":"2023-04-21T19:31:18.311118Z","shell.execute_reply.started":"2023-04-21T19:31:17.620645Z"},"trusted":true},"outputs":[],"source":["labels = np.unique(np.array(train_y))\n","\n","sig_frame_dict = {}\n","for i in labels:\n","    with open('/kaggle/input/train-hist-frames/'+ 'class_'+ str(i) +'_sig_frames.txt', 'r') as readfile:\n","        contents = readfile.read()\n","        lines = contents.splitlines()\n","    for l in lines:\n","        #print(l)\n","        l_arr = l.split(\" \", 1)\n","        sig_frame_dict['/kaggle/input/ucf101/UCF101/UCF-101/'+ l_arr[0]] = eval(l_arr[1])\n","\n","    with open('/kaggle/input/test-hist-frames/'+ 'test_class_'+ str(i) +'_sig_frames.txt', 'r') as read_testfile:\n","        contents = read_testfile.read()\n","        lines = contents.splitlines()\n","    for l in lines:\n","        l_arr = l.split(\" \", 1)\n","        sig_frame_dict['/kaggle/input/ucf101/UCF101/UCF-101/' + l_arr[0]] = eval(l_arr[1])\n","    \n"]},{"cell_type":"code","execution_count":21,"metadata":{"execution":{"iopub.execute_input":"2023-04-21T19:31:18.316236Z","iopub.status.busy":"2023-04-21T19:31:18.315948Z","iopub.status.idle":"2023-04-21T19:31:18.323084Z","shell.execute_reply":"2023-04-21T19:31:18.321876Z","shell.execute_reply.started":"2023-04-21T19:31:18.316208Z"},"trusted":true},"outputs":[{"data":{"text/plain":["[0, 1, 4, 6, 7, 12, 16, 22, 28, 33, 37, 42, 44, 48, 53, 58, 64, 72, 76, 84]"]},"execution_count":21,"metadata":{},"output_type":"execute_result"}],"source":["sig_frame_dict['/kaggle/input/ucf101/UCF101/UCF-101/ApplyEyeMakeup/v_ApplyEyeMakeup_g08_c01.avi']"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{},"source":["# ## **data loader**"]},{"cell_type":"markdown","metadata":{},"source":["## for skip interval/random/adaptive frame selection"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2023-04-21T16:56:26.499151Z","iopub.status.busy":"2023-04-21T16:56:26.498682Z","iopub.status.idle":"2023-04-21T16:56:26.505110Z","shell.execute_reply":"2023-04-21T16:56:26.503363Z","shell.execute_reply.started":"2023-04-21T16:56:26.499111Z"},"trusted":true},"outputs":[],"source":["\n","# cnn_base = keras.applications.resnet.ResNet50(weights=\"imagenet\", include_top=False, input_shape= (224,224,3))\n","\n","# cnn_out = keras.layers.GlobalMaxPool2D()(cnn_base)\n","# cnn = keras.Model(inputs=cnn_base.input, outputs=cnn_out)\n","# cnn.trainable = False"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2023-04-20T09:05:30.419361Z","iopub.status.busy":"2023-04-20T09:05:30.419004Z","iopub.status.idle":"2023-04-20T09:05:30.426966Z","shell.execute_reply":"2023-04-20T09:05:30.426034Z","shell.execute_reply.started":"2023-04-20T09:05:30.419324Z"},"trusted":true},"outputs":[],"source":["# cnn.summary()"]},{"cell_type":"code","execution_count":22,"metadata":{"execution":{"iopub.execute_input":"2023-04-21T19:31:21.578772Z","iopub.status.busy":"2023-04-21T19:31:21.577879Z","iopub.status.idle":"2023-04-21T19:31:21.594833Z","shell.execute_reply":"2023-04-21T19:31:21.593738Z","shell.execute_reply.started":"2023-04-21T19:31:21.578716Z"},"trusted":true},"outputs":[],"source":["def generate_frames_from_videos(video_path, frame_selection = 'skip'):\n","\n","        #CAPTURING FRAMES after EVERY 20 FRAMES OF VIDEOS\n","#         print(video_path, type(video_path))\n","        video1 = cv2.VideoCapture(video_path)\n","        #total_frames = video1.get(cv2.CAP_PROP_FRAME_COUNT)\n","        \n","        if (frame_selection == 'skip'):\n","            frames_total = []\n","            frames_arr = []\n","            while video1.isOpened():\n","                ret, frame = video1.read()\n","\n","                if not ret:  #reached end of video\n","                    break\n","                frames_total.append(frame)\n","\n","            video1.release()\n","            total_frames = len(frames_total)\n","            #print(total_frames)\n","            interval = total_frames // 20\n","\n","            for _ in range (total_frames):\n","                if _ % interval == 0:\n","                    resized_frame = cv2.resize(frames_total[_], (224, 224))\n","                    \n","                    resized_frame = tf.keras.applications.resnet.preprocess_input(resized_frame)\n","                    resized_frame = resized_frame.reshape(1,224,224,3)\n","                    frames_arr.append(cnn.predict(resized_frame, verbose = 0))\n","                if _ >= 19 * interval:\n","                    break\n","\n","            frames_arr = np.squeeze(np.array(frames_arr), axis = 1)\n","            return frames_arr\n","        \n","        \n","        elif (frame_selection == 'random'):\n","            \n","            frames_total = []\n","            frames_arr = []\n","            while video1.isOpened():\n","                ret, frame = video1.read()\n","\n","                if not ret:  #reached end of video\n","                    break\n","                frames_total.append(frame)\n","\n","            video1.release()\n","            total_frames = len(frames_total)\n","            rand_list = random.sample(range(0,total_frames),20)\n","\n","            for _ in sorted(rand_list):\n","                resized_frame = cv2.resize(frames_total[_], (224, 224))\n","                frames_arr.append(resized_frame)\n","            return frames_arr\n","        \n","        \n","        elif (frame_selection == 'hist_difference'):\n","            frames_num = sig_frame_dict[video_path]\n","            #print(len(frames_num))\n","            frame_count = 0\n","            frames_arr = []\n","            \n","            frames_total = []\n","            while video1.isOpened():\n","                ret, frame = video1.read()\n","\n","                if not ret:  #reached end of video\n","                    break\n","                frames_total.append(frame)\n","                \n","            total_frames = len(frames_total)\n","            \n","            actual = []\n","            \n","            for i in range(len(frames_num)):\n","                ind = list(frames_num)[i]\n","                if ind < total_frames:\n","                    actual.append(ind)\n","                else:\n","                    int_ind = np.random.randint(0,total_frames)\n","                    actual.append(int_ind)\n","            if (len(actual)< 20):\n","                actual = actual + list(np.random.randint(0,total_frames,20-len(actual)))\n","                actual = sorted(actual)\n","            for ind in actual:\n","                resized_frame = cv2.resize(frames_total[int(ind)], (224, 224))\n","                frames_arr.append(resized_frame)\n","#                 resized_frame = tf.keras.applications.resnet.preprocess_input(resized_frame)\n","#                 resized_frame = resized_frame.reshape(1,224,224,3)\n","#                 frames_arr.append(cnn.predict(resized_frame, verbose = 0))\n","\n","            video1.release()\n","#             frames_arr = np.squeeze(np.array(frames_arr), axis = 1)\n","            return frames_arr\n","            "]},{"cell_type":"code","execution_count":23,"metadata":{"execution":{"iopub.execute_input":"2023-04-21T19:31:21.795166Z","iopub.status.busy":"2023-04-21T19:31:21.794193Z","iopub.status.idle":"2023-04-21T19:31:21.800027Z","shell.execute_reply":"2023-04-21T19:31:21.798742Z","shell.execute_reply.started":"2023-04-21T19:31:21.795117Z"},"trusted":true},"outputs":[],"source":["# from sklearn.utils import shuffle\n","# train_path,train_labels=shuffle(train_path,train_labels, random_state=42)"]},{"cell_type":"code","execution_count":24,"metadata":{"execution":{"iopub.execute_input":"2023-04-21T19:31:22.067252Z","iopub.status.busy":"2023-04-21T19:31:22.066568Z","iopub.status.idle":"2023-04-21T19:31:22.278725Z","shell.execute_reply":"2023-04-21T19:31:22.277593Z","shell.execute_reply.started":"2023-04-21T19:31:22.067206Z"},"trusted":true},"outputs":[{"data":{"text/plain":["(20, 224, 224, 3)"]},"execution_count":24,"metadata":{},"output_type":"execute_result"}],"source":["z = generate_frames_from_videos('/kaggle/input/ucf101/UCF101/UCF-101/SalsaSpin/v_SalsaSpin_g14_c03.avi', 'hist_difference')\n","np.array(z).shape"]},{"cell_type":"code","execution_count":25,"metadata":{"execution":{"iopub.execute_input":"2023-04-21T19:31:22.593973Z","iopub.status.busy":"2023-04-21T19:31:22.592660Z","iopub.status.idle":"2023-04-21T19:31:22.645602Z","shell.execute_reply":"2023-04-21T19:31:22.644551Z","shell.execute_reply.started":"2023-04-21T19:31:22.593926Z"},"trusted":true},"outputs":[],"source":["folder_path = '/kaggle/input/ucf101/'\n","\n","#             print(str(folder_path + 'UCF101/UCF-101/' + str(video_path, 'UTF-8')))\n","frame_arr = generate_frames_from_videos(str(folder_path + 'UCF101/UCF-101/' + str(train_path_list[1])), 'hist_difference')"]},{"cell_type":"code","execution_count":26,"metadata":{"execution":{"iopub.execute_input":"2023-04-21T19:31:24.088713Z","iopub.status.busy":"2023-04-21T19:31:24.087503Z","iopub.status.idle":"2023-04-21T19:31:24.097646Z","shell.execute_reply":"2023-04-21T19:31:24.096404Z","shell.execute_reply.started":"2023-04-21T19:31:24.088640Z"},"trusted":true},"outputs":[{"data":{"text/plain":["(20, 224, 224, 3)"]},"execution_count":26,"metadata":{},"output_type":"execute_result"}],"source":["np.array(frame_arr).shape"]},{"cell_type":"code","execution_count":27,"metadata":{"execution":{"iopub.execute_input":"2023-04-21T19:31:24.312372Z","iopub.status.busy":"2023-04-21T19:31:24.311410Z","iopub.status.idle":"2023-04-21T19:31:24.317178Z","shell.execute_reply":"2023-04-21T19:31:24.316048Z","shell.execute_reply.started":"2023-04-21T19:31:24.312337Z"},"trusted":true},"outputs":[],"source":["import os"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":28,"metadata":{"execution":{"iopub.execute_input":"2023-04-21T19:31:27.476237Z","iopub.status.busy":"2023-04-21T19:31:27.475539Z","iopub.status.idle":"2023-04-21T19:31:27.483441Z","shell.execute_reply":"2023-04-21T19:31:27.482261Z","shell.execute_reply.started":"2023-04-21T19:31:27.476197Z"},"trusted":true},"outputs":[],"source":["def video_data_generator(X=train_path_list, Y=train_y_hot, frame_selection = 'hist_difference'):\n","        indices = np.arange(len(X))\n","        np.random.shuffle(indices)\n","        X_paths = [X[i] for i in indices]\n","        labels = [Y[i] for i in indices]\n","\n","        folder_path = '/kaggle/input/ucf101/'\n","        for i in range (len(X)):\n","            video_path = X_paths[i]\n","            label= labels[i]\n","#             print(type(frame_selection))\n","            frame_arr = generate_frames_from_videos(str(os.path.join(folder_path, \"UCF101/UCF-101/\", str(video_path, 'UTF-8'))), frame_selection.decode())\n","            yield np.array(frame_arr), label\n","\n"]},{"cell_type":"markdown","metadata":{},"source":["### making an instance of the generator for hist_difference"]},{"cell_type":"code","execution_count":29,"metadata":{"execution":{"iopub.execute_input":"2023-04-21T19:31:29.433134Z","iopub.status.busy":"2023-04-21T19:31:29.431977Z","iopub.status.idle":"2023-04-21T19:31:32.050637Z","shell.execute_reply":"2023-04-21T19:31:32.049628Z","shell.execute_reply.started":"2023-04-21T19:31:29.433091Z"},"trusted":true},"outputs":[],"source":["#genertor converts every argument into bytes\n","\n","dataset_train = tf.data.Dataset.from_generator(\n"," video_data_generator,\n"," args = (train_path_list,train_y_hot,'hist_difference'),\n"," output_signature=(\n","     tf.TensorSpec(shape=(20, 224,224,3), dtype=tf.float64),\n","     tf.TensorSpec(shape=(21,), dtype=tf.int16)\n","     )\n"," ).batch(batch_size = 32).prefetch(tf.data.AUTOTUNE)\n","dataset_test = tf.data.Dataset.from_generator(\n"," video_data_generator,\n"," args = (test_path_list,test_y_hot,'hist_difference'),\n"," output_signature=(\n","     tf.TensorSpec(shape=(20, 224,224,3), dtype=tf.float64),\n","     tf.TensorSpec(shape=(21,))\n","     )\n"," ).batch(batch_size = 32).prefetch(tf.data.AUTOTUNE)"]},{"cell_type":"code","execution_count":23,"metadata":{"execution":{"iopub.execute_input":"2023-04-21T17:39:47.827117Z","iopub.status.busy":"2023-04-21T17:39:47.826759Z","iopub.status.idle":"2023-04-21T17:39:47.832676Z","shell.execute_reply":"2023-04-21T17:39:47.831737Z","shell.execute_reply.started":"2023-04-21T17:39:47.827077Z"},"trusted":true},"outputs":[],"source":[]},{"cell_type":"code","execution_count":18,"metadata":{"execution":{"iopub.execute_input":"2023-04-21T17:02:05.165359Z","iopub.status.busy":"2023-04-21T17:02:05.164693Z","iopub.status.idle":"2023-04-21T17:02:05.177018Z","shell.execute_reply":"2023-04-21T17:02:05.175994Z","shell.execute_reply.started":"2023-04-21T17:02:05.165324Z"},"trusted":true},"outputs":[],"source":[]},{"cell_type":"code","execution_count":19,"metadata":{"execution":{"iopub.execute_input":"2023-04-21T17:02:05.327014Z","iopub.status.busy":"2023-04-21T17:02:05.326391Z","iopub.status.idle":"2023-04-21T17:02:05.334449Z","shell.execute_reply":"2023-04-21T17:02:05.333252Z","shell.execute_reply.started":"2023-04-21T17:02:05.326977Z"},"trusted":true},"outputs":[{"data":{"text/plain":["[0, 12, 24, 36, 37, 40, 43, 45, 47, 48, 56, 60, 65, 68, 72, 73, 75, 78, 80, 81]"]},"execution_count":19,"metadata":{},"output_type":"execute_result"}],"source":["sig_frame_dict[folder_path+ 'UCF101/UCF-101/' + 'Basketball/v_Basketball_g09_c01.avi']"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{},"source":["## Functional API"]},{"cell_type":"markdown","metadata":{},"source":["## Resnet50"]},{"cell_type":"code","execution_count":19,"metadata":{"execution":{"iopub.execute_input":"2023-04-20T16:49:11.470340Z","iopub.status.busy":"2023-04-20T16:49:11.469593Z","iopub.status.idle":"2023-04-20T16:49:14.964238Z","shell.execute_reply":"2023-04-20T16:49:14.963227Z","shell.execute_reply.started":"2023-04-20T16:49:11.470303Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n","94765736/94765736 [==============================] - 1s 0us/step\n"]}],"source":["resnet_pt_model = tf.keras.applications.resnet.ResNet50(\n","    include_top=False,\n","    weights='imagenet'\n",")\n","resnet_pt_model.trainable = False\n","model_pret_x = Sequential()\n","model_pret_x.add(TimeDistributed(resnet_pt_model, input_shape= (20,224,224,3)))\n","\n","model_pret_x.add(TimeDistributed(GlobalMaxPool2D()))\n","\n","model_pret_x.add(LSTM(128))\n","\n","# model_pret_x.add(Dense(128, activation = 'sigmoid'))\n","\n","# model_pret_x.add(Dense(64, activation = 'sigmoid'))\n","\n","model_pret_x.add(Dense(len(req_classes), activation = 'softmax'))\n"]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2023-04-20T09:07:45.260744Z","iopub.status.busy":"2023-04-20T09:07:45.260369Z","iopub.status.idle":"2023-04-20T09:07:45.575084Z","shell.execute_reply":"2023-04-20T09:07:45.574002Z","shell.execute_reply.started":"2023-04-20T09:07:45.260712Z"},"trusted":true},"outputs":[],"source":["\n","\n","# frame_features_input = keras.layers.Input(shape = (20,100352))\n","\n","# encoded_sequence = keras.layers.LSTM(128, input_shape = (20,100352), return_sequences = True)(frame_features_input)\n","\n","# td_dense_layer = keras.layers.TimeDistributed(keras.layers.Dense(32, activation = 'relu'))(encoded_sequence)\n","\n","# gmp_layer = keras.layers.GlobalMaxPool1D()(td_dense_layer)\n","\n","# outputs = keras.layers.Dense(len(req_classes), activation=\"softmax\")(gmp_layer)\n","\n","# model_resnet_lstm_ = keras.Model(frame_features_input, outputs)"]},{"cell_type":"code","execution_count":20,"metadata":{"execution":{"iopub.execute_input":"2023-04-20T16:49:16.545632Z","iopub.status.busy":"2023-04-20T16:49:16.545233Z","iopub.status.idle":"2023-04-20T16:49:16.550723Z","shell.execute_reply":"2023-04-20T16:49:16.549580Z","shell.execute_reply.started":"2023-04-20T16:49:16.545598Z"},"trusted":true},"outputs":[],"source":["early_stopping_callback = EarlyStopping(monitor = 'val_loss', patience = 5, mode = 'min', restore_best_weights = True)"]},{"cell_type":"code","execution_count":36,"metadata":{"execution":{"iopub.execute_input":"2023-04-20T16:54:27.767699Z","iopub.status.busy":"2023-04-20T16:54:27.766742Z","iopub.status.idle":"2023-04-20T16:54:27.783005Z","shell.execute_reply":"2023-04-20T16:54:27.782050Z","shell.execute_reply.started":"2023-04-20T16:54:27.767661Z"},"trusted":true},"outputs":[],"source":["model_pret_x.compile(loss = 'categorical_crossentropy', optimizer = keras.optimizers.SGD()\n","                     , metrics = [\"accuracy\"])"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":37,"metadata":{"execution":{"iopub.execute_input":"2023-04-20T16:54:28.060102Z","iopub.status.busy":"2023-04-20T16:54:28.059061Z","iopub.status.idle":"2023-04-20T16:54:28.105420Z","shell.execute_reply":"2023-04-20T16:54:28.104577Z","shell.execute_reply.started":"2023-04-20T16:54:28.060063Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," time_distributed (TimeDistr  (None, 20, 7, 7, 2048)   23587712  \n"," ibuted)                                                         \n","                                                                 \n"," time_distributed_1 (TimeDis  (None, 20, 2048)         0         \n"," tributed)                                                       \n","                                                                 \n"," lstm (LSTM)                 (None, 128)               1114624   \n","                                                                 \n"," dense (Dense)               (None, 21)                2709      \n","                                                                 \n","=================================================================\n","Total params: 24,705,045\n","Trainable params: 1,117,333\n","Non-trainable params: 23,587,712\n","_________________________________________________________________\n"]}],"source":["model_pret_x.summary()"]},{"cell_type":"code","execution_count":102,"metadata":{"execution":{"iopub.execute_input":"2023-04-20T17:48:16.162302Z","iopub.status.busy":"2023-04-20T17:48:16.161886Z","iopub.status.idle":"2023-04-20T17:48:16.214235Z","shell.execute_reply":"2023-04-20T17:48:16.213045Z","shell.execute_reply.started":"2023-04-20T17:48:16.162267Z"},"scrolled":true,"trusted":true},"outputs":[],"source":["a=generate_frames_from_videos(\"/kaggle/input/ucf101/UCF101/UCF-101/PlayingSitar/v_PlayingSitar_g09_c07.avi\", 'hist_difference')"]},{"cell_type":"code","execution_count":103,"metadata":{"execution":{"iopub.execute_input":"2023-04-20T17:48:17.825244Z","iopub.status.busy":"2023-04-20T17:48:17.824851Z","iopub.status.idle":"2023-04-20T17:48:17.834964Z","shell.execute_reply":"2023-04-20T17:48:17.833406Z","shell.execute_reply.started":"2023-04-20T17:48:17.825211Z"},"trusted":true},"outputs":[{"data":{"text/plain":["(20, 224, 224, 3)"]},"execution_count":103,"metadata":{},"output_type":"execute_result"}],"source":["np.array(a).shape"]},{"cell_type":"code","execution_count":122,"metadata":{"execution":{"iopub.execute_input":"2023-04-20T17:59:11.432470Z","iopub.status.busy":"2023-04-20T17:59:11.431780Z","iopub.status.idle":"2023-04-20T18:21:20.540899Z","shell.execute_reply":"2023-04-20T18:21:20.539803Z","shell.execute_reply.started":"2023-04-20T17:59:11.432429Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/3\n","95/95 [==============================] - 445s 5s/step - loss: 2.1085 - accuracy: 0.4138 - val_loss: 1.8075 - val_accuracy: 0.4703\n","Epoch 2/3\n","95/95 [==============================] - 402s 4s/step - loss: 1.4789 - accuracy: 0.6353 - val_loss: 1.4564 - val_accuracy: 0.6178\n","Epoch 3/3\n","95/95 [==============================] - 407s 4s/step - loss: 1.1076 - accuracy: 0.7697 - val_loss: 1.2227 - val_accuracy: 0.7125\n"]}],"source":["hist_pret_x = model_pret_x.fit(dataset_train, epochs=3,validation_data=dataset_test)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{},"source":["# EfficientNetV2L"]},{"cell_type":"code","execution_count":24,"metadata":{"execution":{"iopub.execute_input":"2023-04-21T17:39:53.316845Z","iopub.status.busy":"2023-04-21T17:39:53.316119Z","iopub.status.idle":"2023-04-21T17:40:12.950470Z","shell.execute_reply":"2023-04-21T17:40:12.949203Z","shell.execute_reply.started":"2023-04-21T17:39:53.316805Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/efficientnet_v2/efficientnetv2-l_notop.h5\n","473176280/473176280 [==============================] - 3s 0us/step\n"]}],"source":["eff_net_ptmodel = tf.keras.applications.efficientnet_v2.EfficientNetV2L(\n","    include_top=False,\n","    weights='imagenet'\n",")\n","eff_net_ptmodel.trainable = False\n","model_pret_x = Sequential()\n","model_pret_x.add(TimeDistributed(eff_net_ptmodel, input_shape= (20,224,224,3)))\n","\n","model_pret_x.add(TimeDistributed(GlobalMaxPool2D()))\n","\n","model_pret_x.add(LSTM(128))\n","\n","# model_pret_x.add(Dense(128, activation = 'sigmoid'))\n","\n","# model_pret_x.add(Dense(64, activation = 'sigmoid'))\n","\n","model_pret_x.add(Dense(len(req_classes), activation = 'softmax'))\n"]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2023-04-20T09:07:45.260744Z","iopub.status.busy":"2023-04-20T09:07:45.260369Z","iopub.status.idle":"2023-04-20T09:07:45.575084Z","shell.execute_reply":"2023-04-20T09:07:45.574002Z","shell.execute_reply.started":"2023-04-20T09:07:45.260712Z"},"trusted":true},"outputs":[],"source":["\n","\n","# frame_features_input = keras.layers.Input(shape = (20,100352))\n","\n","# encoded_sequence = keras.layers.LSTM(128, input_shape = (20,100352), return_sequences = True)(frame_features_input)\n","\n","# td_dense_layer = keras.layers.TimeDistributed(keras.layers.Dense(32, activation = 'relu'))(encoded_sequence)\n","\n","# gmp_layer = keras.layers.GlobalMaxPool1D()(td_dense_layer)\n","\n","# outputs = keras.layers.Dense(len(req_classes), activation=\"softmax\")(gmp_layer)\n","\n","# model_resnet_lstm_ = keras.Model(frame_features_input, outputs)"]},{"cell_type":"code","execution_count":25,"metadata":{"execution":{"iopub.execute_input":"2023-04-21T17:40:35.489074Z","iopub.status.busy":"2023-04-21T17:40:35.487996Z","iopub.status.idle":"2023-04-21T17:40:35.494675Z","shell.execute_reply":"2023-04-21T17:40:35.493393Z","shell.execute_reply.started":"2023-04-21T17:40:35.489023Z"},"trusted":true},"outputs":[],"source":["early_stopping_callback = EarlyStopping(monitor = 'val_loss', patience = 5, mode = 'min', restore_best_weights = True)"]},{"cell_type":"code","execution_count":26,"metadata":{"execution":{"iopub.execute_input":"2023-04-21T17:40:35.852302Z","iopub.status.busy":"2023-04-21T17:40:35.851230Z","iopub.status.idle":"2023-04-21T17:40:35.887816Z","shell.execute_reply":"2023-04-21T17:40:35.886827Z","shell.execute_reply.started":"2023-04-21T17:40:35.852243Z"},"trusted":true},"outputs":[],"source":["model_pret_x.compile(loss = 'categorical_crossentropy', optimizer = keras.optimizers.SGD()\n","                     , metrics = [\"accuracy\"])"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":27,"metadata":{"execution":{"iopub.execute_input":"2023-04-21T17:40:38.902237Z","iopub.status.busy":"2023-04-21T17:40:38.901859Z","iopub.status.idle":"2023-04-21T17:40:38.976764Z","shell.execute_reply":"2023-04-21T17:40:38.975703Z","shell.execute_reply.started":"2023-04-21T17:40:38.902205Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," time_distributed (TimeDistr  (None, 20, 7, 7, 1280)   117746848 \n"," ibuted)                                                         \n","                                                                 \n"," time_distributed_1 (TimeDis  (None, 20, 1280)         0         \n"," tributed)                                                       \n","                                                                 \n"," lstm (LSTM)                 (None, 128)               721408    \n","                                                                 \n"," dense (Dense)               (None, 21)                2709      \n","                                                                 \n","=================================================================\n","Total params: 118,470,965\n","Trainable params: 724,117\n","Non-trainable params: 117,746,848\n","_________________________________________________________________\n"]}],"source":["model_pret_x.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-04-20T20:00:21.318203Z","iopub.status.busy":"2023-04-20T20:00:21.317174Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/5\n"]},{"name":"stderr","output_type":"stream","text":["2023-04-20 20:00:57.189074: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape insequential/time_distributed/efficientnetv2-l/block1b_drop/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"]},{"name":"stdout","output_type":"stream","text":["95/95 [==============================] - 671s 7s/step - loss: 2.2516 - accuracy: 0.3598 - val_loss: 2.0027 - val_accuracy: 0.4366\n","Epoch 2/5\n","95/95 [==============================] - 552s 6s/step - loss: 1.7380 - accuracy: 0.5305 - val_loss: 1.7072 - val_accuracy: 0.5445\n","Epoch 3/5\n","95/95 [==============================] - 567s 6s/step - loss: 1.3847 - accuracy: 0.6488 - val_loss: 1.3006 - val_accuracy: 0.6722\n","Epoch 4/5\n","84/95 [=========================>....] - ETA: 46s - loss: 1.1022 - accuracy: 0.7362"]}],"source":["hist_pret_x = model_pret_x.fit(dataset_train, epochs=5,validation_data=dataset_test)"]},{"cell_type":"code","execution_count":60,"metadata":{"execution":{"iopub.execute_input":"2023-04-21T17:55:25.012128Z","iopub.status.busy":"2023-04-21T17:55:25.011765Z","iopub.status.idle":"2023-04-21T17:56:38.854248Z","shell.execute_reply":"2023-04-21T17:56:38.852876Z","shell.execute_reply.started":"2023-04-21T17:55:25.012096Z"},"trusted":true},"outputs":[],"source":["model_pret_x = tf.keras.models.load_model(\"/kaggle/input/saved-dataset/eff_net_lstm_hist_1.h5\")"]},{"cell_type":"code","execution_count":61,"metadata":{"execution":{"iopub.execute_input":"2023-04-21T17:56:58.460545Z","iopub.status.busy":"2023-04-21T17:56:58.459867Z","iopub.status.idle":"2023-04-21T18:44:48.419818Z","shell.execute_reply":"2023-04-21T18:44:48.418734Z","shell.execute_reply.started":"2023-04-21T17:56:58.460507Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/5\n"]},{"name":"stderr","output_type":"stream","text":["2023-04-21 17:57:16.203827: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape insequential/time_distributed/efficientnetv2-l/block1b_drop/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"]},{"name":"stdout","output_type":"stream","text":["95/95 [==============================] - 613s 6s/step - loss: 0.8267 - accuracy: 0.8194 - val_loss: 0.9783 - val_accuracy: 0.7496\n","Epoch 2/5\n","95/95 [==============================] - 552s 6s/step - loss: 0.6782 - accuracy: 0.8629 - val_loss: 0.9284 - val_accuracy: 0.7611\n","Epoch 3/5\n","95/95 [==============================] - 562s 6s/step - loss: 0.5925 - accuracy: 0.8804 - val_loss: 0.8576 - val_accuracy: 0.7776\n","Epoch 4/5\n","95/95 [==============================] - 542s 6s/step - loss: 0.5336 - accuracy: 0.8956 - val_loss: 0.8282 - val_accuracy: 0.7891\n","Epoch 5/5\n","95/95 [==============================] - 554s 6s/step - loss: 0.4816 - accuracy: 0.9054 - val_loss: 0.8151 - val_accuracy: 0.7743\n"]}],"source":["hist_pret_x = model_pret_x.fit(dataset_train, epochs=5,validation_data=dataset_test)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{},"source":["## Attention"]},{"cell_type":"code","execution_count":38,"metadata":{"execution":{"iopub.execute_input":"2023-04-19T20:18:58.779385Z","iopub.status.busy":"2023-04-19T20:18:58.778658Z","iopub.status.idle":"2023-04-19T20:18:58.784566Z","shell.execute_reply":"2023-04-19T20:18:58.783331Z","shell.execute_reply.started":"2023-04-19T20:18:58.779346Z"},"trusted":true},"outputs":[],"source":["from tensorflow.keras.layers import Input, Dense, Permute, Multiply"]},{"cell_type":"code","execution_count":39,"metadata":{"execution":{"iopub.execute_input":"2023-04-19T20:18:59.087631Z","iopub.status.busy":"2023-04-19T20:18:59.086847Z","iopub.status.idle":"2023-04-19T20:18:59.093503Z","shell.execute_reply":"2023-04-19T20:18:59.092418Z","shell.execute_reply.started":"2023-04-19T20:18:59.087588Z"},"trusted":true},"outputs":[],"source":["\n"]},{"cell_type":"code","execution_count":30,"metadata":{"execution":{"iopub.execute_input":"2023-04-21T19:33:43.727624Z","iopub.status.busy":"2023-04-21T19:33:43.726579Z","iopub.status.idle":"2023-04-21T19:34:13.235662Z","shell.execute_reply":"2023-04-21T19:34:13.234636Z","shell.execute_reply.started":"2023-04-21T19:33:43.727582Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/efficientnet_v2/efficientnetv2-l_notop.h5\n","473176280/473176280 [==============================] - 20s 0us/step\n"]}],"source":["eff_net_ptmodel = tf.keras.applications.efficientnet_v2.EfficientNetV2L(\n","    include_top=False,\n","    weights='imagenet'\n",")\n","eff_net_ptmodel.trainable = False"]},{"cell_type":"code","execution_count":34,"metadata":{"execution":{"iopub.execute_input":"2023-04-21T20:06:55.706478Z","iopub.status.busy":"2023-04-21T20:06:55.705785Z","iopub.status.idle":"2023-04-21T20:07:03.688090Z","shell.execute_reply":"2023-04-21T20:07:03.684733Z","shell.execute_reply.started":"2023-04-21T20:06:55.706441Z"},"trusted":true},"outputs":[],"source":["\n","# encoding the images -- the model\n","eff_out = keras.layers.GlobalAveragePooling2D()(eff_net_ptmodel.output)\n","encoder = keras.Model(inputs = eff_net_ptmodel.input, outputs= eff_out)\n","\n","\n","input_feature = keras.layers.Input(shape = [20, 224, 224, 3])\n","\n","\n","#attention layer connecting the \n","encoded_img =keras.layers.TimeDistributed(encoder)(input_feature)\n","query_img = keras.layers.TimeDistributed(keras.layers.Dense(128, activation = 'relu'))(encoded_img)\n","key_img = keras.layers.TimeDistributed(keras.layers.Dense(128, activation = 'relu'))(encoded_img)\n","\n","att_out = keras.layers.Attention()([query_img, key_img])\n","\n","concat_layer = keras.layers.Concatenate()([att_out, encoded_img])\n","\n","encoded_sequence = keras.layers.Bidirectional(keras.layers.LSTM(128))(concat_layer)\n","\n","lstm_dense_td = keras.layers.Dense(64, activation = 'relu')(encoded_sequence)\n","\n","outputs = keras.layers.Dense(len(req_classes), activation=\"softmax\")(lstm_dense_td)\n","\n","model_effnet_att_lstm = keras.Model(input_feature, outputs)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":35,"metadata":{"execution":{"iopub.execute_input":"2023-04-21T20:07:04.999925Z","iopub.status.busy":"2023-04-21T20:07:04.997368Z","iopub.status.idle":"2023-04-21T20:07:05.161654Z","shell.execute_reply":"2023-04-21T20:07:05.160582Z","shell.execute_reply.started":"2023-04-21T20:07:04.999881Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"model_3\"\n","__________________________________________________________________________________________________\n"," Layer (type)                   Output Shape         Param #     Connected to                     \n","==================================================================================================\n"," input_4 (InputLayer)           [(None, 20, 224, 22  0           []                               \n","                                4, 3)]                                                            \n","                                                                                                  \n"," time_distributed_7 (TimeDistri  (None, 20, 1280)    117746848   ['input_4[0][0]']                \n"," buted)                                                                                           \n","                                                                                                  \n"," time_distributed_8 (TimeDistri  (None, 20, 128)     163968      ['time_distributed_7[0][0]']     \n"," buted)                                                                                           \n","                                                                                                  \n"," time_distributed_9 (TimeDistri  (None, 20, 128)     163968      ['time_distributed_7[0][0]']     \n"," buted)                                                                                           \n","                                                                                                  \n"," attention_2 (Attention)        (None, 20, 128)      0           ['time_distributed_8[0][0]',     \n","                                                                  'time_distributed_9[0][0]']     \n","                                                                                                  \n"," concatenate_2 (Concatenate)    (None, 20, 1408)     0           ['attention_2[0][0]',            \n","                                                                  'time_distributed_7[0][0]']     \n","                                                                                                  \n"," bidirectional_2 (Bidirectional  (None, 256)         1573888     ['concatenate_2[0][0]']          \n"," )                                                                                                \n","                                                                                                  \n"," dense_9 (Dense)                (None, 64)           16448       ['bidirectional_2[0][0]']        \n","                                                                                                  \n"," dense_10 (Dense)               (None, 21)           1365        ['dense_9[0][0]']                \n","                                                                                                  \n","==================================================================================================\n","Total params: 119,666,485\n","Trainable params: 1,919,637\n","Non-trainable params: 117,746,848\n","__________________________________________________________________________________________________\n"]}],"source":["model_effnet_att_lstm.summary()"]},{"cell_type":"code","execution_count":36,"metadata":{"execution":{"iopub.execute_input":"2023-04-21T20:08:38.066592Z","iopub.status.busy":"2023-04-21T20:08:38.066095Z","iopub.status.idle":"2023-04-21T20:08:38.077443Z","shell.execute_reply":"2023-04-21T20:08:38.075764Z","shell.execute_reply.started":"2023-04-21T20:08:38.066541Z"},"trusted":true},"outputs":[],"source":["early_stopping_callback = EarlyStopping(monitor = 'val_loss', patience = 5, mode = 'min', restore_best_weights = True)"]},{"cell_type":"code","execution_count":37,"metadata":{"execution":{"iopub.execute_input":"2023-04-21T20:09:30.089466Z","iopub.status.busy":"2023-04-21T20:09:30.088511Z","iopub.status.idle":"2023-04-21T20:09:30.126169Z","shell.execute_reply":"2023-04-21T20:09:30.125220Z","shell.execute_reply.started":"2023-04-21T20:09:30.089428Z"},"trusted":true},"outputs":[],"source":["model_effnet_att_lstm.compile(loss = 'categorical_crossentropy', optimizer = keras.optimizers.Adam()\n","                     , metrics = [\"accuracy\"])"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-04-21T20:10:14.364764Z","iopub.status.busy":"2023-04-21T20:10:14.363573Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/5\n"]},{"name":"stderr","output_type":"stream","text":["2023-04-21 20:10:49.314481: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inmodel_3/time_distributed_7/model_2/block1b_drop/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"]},{"name":"stdout","output_type":"stream","text":["95/95 [==============================] - 653s 6s/step - loss: 0.7489 - accuracy: 0.8033 - val_loss: 0.4530 - val_accuracy: 0.8674\n","Epoch 2/5\n","30/95 [========>.....................] - ETA: 4:32 - loss: 0.1416 - accuracy: 0.9604"]}],"source":["model_effnet_att_lstm.fit(dataset_train, epochs=5,validation_data=dataset_test)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.12"}},"nbformat":4,"nbformat_minor":4}
